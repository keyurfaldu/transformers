{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_superglue_mcqa import (\n",
    "    MultipleChoiceDataset, \n",
    "    Split, \n",
    "    processors, \n",
    "    superglue_mcqa_output_modes, \n",
    "    superglue_mcqa_tasks_num_labels, \n",
    "    superglue_mcqa_compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/06/2020 13:00:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: copa Labels: 2 , Output classification\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: str = field(metadata={\"help\": \"The name of the task to train on: \" + \", \".join(processors.keys())})\n",
    "    data_dir: str = field(metadata={\"help\": \"Should contain the data files for the task.\"})\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.task_name = self.task_name.lower()\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_NAME = \"bert-base-cased\"\n",
    "DATESTAMP = \"20200805\"\n",
    "SUPER_GLUE_DIR = \"/home/keyur/medhas/superglue_data/\"\n",
    "TASK_NAME = \"COPA\"\n",
    "PER_DEVICE_BATCH_SIZE = 32\n",
    "EXPERIMENT_DIR=\"/mnt/data/medhas/glue_experiments/%s/%s\"%(MODEL_NAME, DATESTAMP)\n",
    "\n",
    "custom_sysargv = [\n",
    "\"--model_name_or_path=%s\"%MODEL_NAME,\n",
    "\"--task_name=%s\"%TASK_NAME,\n",
    "\"--do_train\",\n",
    "\"--do_eval\",\n",
    "\"--data_dir=%s\"%os.path.join(SUPER_GLUE_DIR, TASK_NAME),\n",
    "\"--max_seq_length=256\",\n",
    "\"--per_device_train_batch_size=%s\"%PER_DEVICE_BATCH_SIZE,\n",
    "\"--learning_rate=10e-5\",\n",
    "\"--num_train_epochs=10\",\n",
    "\"--output_dir=%s\"%os.path.join(EXPERIMENT_DIR, TASK_NAME),\n",
    "\"--logging_dir=%s/logs\"%os.path.join(EXPERIMENT_DIR, TASK_NAME),\n",
    "\"--logging_steps=7\",\n",
    "\"--evaluate_during_training\",\n",
    "\"--eval_step=7\",\n",
    "\"--save_total_limit=2\",\n",
    "\"--save_steps=1000\",\n",
    "\"--gradient_accumulation_steps=1\",\n",
    "\"--overwrite_output_dir\"\n",
    "]\n",
    "\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args=custom_sysargv)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.WARN if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "set_seed(training_args.seed)\n",
    "training_args.seed\n",
    "\n",
    "num_labels = superglue_mcqa_tasks_num_labels[data_args.task_name]\n",
    "output_mode = superglue_mcqa_output_modes[data_args.task_name]\n",
    "print (\"Task:\", data_args.task_name, \"Labels:\", num_labels, ', Output', output_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else     model_args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        finetuning_task=data_args.task_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/06/2020 13:00:12 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "08/06/2020 13:00:12 - WARNING - transformers.modeling_utils -   Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    ")\n",
    "#model = BertForNLI.from_pretrained(model_args.model_name_or_path, config=config, cache_dir=model_args.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultipleChoiceDataset(data_args.data_dir, tokenizer=tokenizer, \n",
    "                    task=data_args.task_name, max_seq_length=data_args.max_seq_length, \n",
    "                    overwrite_cache=data_args.overwrite_cache, mode=Split.train,) if training_args.do_train else None\n",
    "\n",
    "eval_dataset = MultipleChoiceDataset(data_args.data_dir, tokenizer=tokenizer, \n",
    "                    task=data_args.task_name, max_seq_length=data_args.max_seq_length, \n",
    "                    overwrite_cache=data_args.overwrite_cache, mode=Split.dev,) if training_args.do_eval else None\n",
    "\n",
    "test_dataset = MultipleChoiceDataset(data_args.data_dir, tokenizer=tokenizer, \n",
    "                    task=data_args.task_name, max_seq_length=data_args.max_seq_length, \n",
    "                    overwrite_cache=data_args.overwrite_cache, mode=Split.test,) if training_args.do_predict else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EvalPrediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a31352cce62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EvalPrediction' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p: EvalPrediction) -> Dict:\n",
    "    if output_mode == \"classification\":\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "    elif output_mode == \"regression\":\n",
    "        preds = np.squeeze(p.predictions)\n",
    "    return superglue_mcqa_compute_metrics(data_args.task_name, preds, p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0bb8cf7e77498389f41e5a4be676a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76556ec5a7fe491a9c25813730abcda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keyur/anaconda3/envs/medhas02/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6755454284804208, 'learning_rate': 9e-05, 'epoch': 1.0, 'step': 7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf7f27ee50347fe8d9630c38b17cb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.6655420320374625, 'eval_acc': 0.6767676767676768, 'epoch': 1.0, 'step': 7}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c15673873574f4383529b0231084be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5778663158416748, 'learning_rate': 8e-05, 'epoch': 2.0, 'step': 14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016bffab8f704ab2ab33ebb3b3c0c46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.5933130426066262, 'eval_acc': 0.6868686868686869, 'epoch': 2.0, 'step': 14}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bb4ebfcdaa40d7b8b49a153c0f3851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3283346039908273, 'learning_rate': 7e-05, 'epoch': 3.0, 'step': 21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600c873389f74085825f3fd8f2887971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.6136210943971362, 'eval_acc': 0.6767676767676768, 'epoch': 3.0, 'step': 21}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b43590f5a04800b83c703b6084b879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.14850332694394247, 'learning_rate': 6e-05, 'epoch': 4.0, 'step': 28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52c91a945544c0287533a15380e777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.6837093446935926, 'eval_acc': 0.696969696969697, 'epoch': 4.0, 'step': 28}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b4c0f084404cd5991d7e4c3d89cdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053197213049445836, 'learning_rate': 5e-05, 'epoch': 5.0, 'step': 35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64d2420ef8f45c195b1fd9377d805ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8295340878622872, 'eval_acc': 0.6060606060606061, 'epoch': 5.0, 'step': 35}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3bbaa1a6e74ff3be5643b2a1b50515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.026403906356011118, 'learning_rate': 4e-05, 'epoch': 6.0, 'step': 42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0636262ca32e4aa78b9c6ece460017fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 1.0115699768066406, 'eval_acc': 0.6060606060606061, 'epoch': 6.0, 'step': 42}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc67bd00d6824e84a90481e04889af1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.014633575820231013, 'learning_rate': 3e-05, 'epoch': 7.0, 'step': 49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77a74b0fb3c4cda967054d06ae66b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.9866847183023181, 'eval_acc': 0.5959595959595959, 'epoch': 7.0, 'step': 49}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac3f60950144fbe96b0c5b3f7fd0ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.011814989848062396, 'learning_rate': 2e-05, 'epoch': 8.0, 'step': 56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3480e78e2b80483a804988f94e73a987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 1.116514767919268, 'eval_acc': 0.6262626262626263, 'epoch': 8.0, 'step': 56}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece0e9f424e74b0399e919d4c883c9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.01878399002764906, 'learning_rate': 1e-05, 'epoch': 9.0, 'step': 63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1ba0d59112457d935e5c0ca8ad54df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 1.1544829777308874, 'eval_acc': 0.6565656565656566, 'epoch': 9.0, 'step': 63}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df142de294e545848c0b8c398233b16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=7.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0099432860401326, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 70}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64929bdfda44acc9ea145e688c9400f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 1.1537462217467171, 'eval_acc': 0.6565656565656566, 'epoch': 10.0, 'step': 70}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if training_args.do_train:\n",
    "        trainer.train(\n",
    "            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
    "        )\n",
    "        trainer.save_model()\n",
    "        # For convenience, we also re-save the tokenizer to the same directory,\n",
    "        # so that you can share your model easily on huggingface.co/models =)\n",
    "        if trainer.is_world_master():\n",
    "            tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Tensor([1,3,4]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_results = {}\n",
    "if training_args.do_eval:\n",
    "    #logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_datasets = [eval_dataset]\n",
    "\n",
    "    for eval_dataset in eval_datasets:\n",
    "        eval_result = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "        output_eval_file = os.path.join(\n",
    "            training_args.output_dir, f\"eval_results_{eval_dataset.args.task_name}.txt\"\n",
    "        )\n",
    "        if trainer.is_world_master():\n",
    "            with open(output_eval_file, \"w\") as writer:\n",
    "                #logger.info(\"***** Eval results {} *****\".format(eval_dataset.args.task_name))\n",
    "                for key, value in eval_result.items():\n",
    "                    #logger.info(\"  %s = %s\", key, value)\n",
    "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
    "\n",
    "        eval_results.update(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medhas02",
   "language": "python",
   "name": "medhas02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
