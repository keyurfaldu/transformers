{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    squad_convert_examples_to_features,\n",
    ")\n",
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--threads'], dest='threads', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='multiple threads for converting example to features', metavar=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required parameters\n",
    "parser.add_argument(\n",
    "    \"--model_type\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Model type selected in the list: \" + \", \".join(MODEL_TYPES),\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_name_or_path\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"The output directory where the model checkpoints and predictions will be written.\",\n",
    ")\n",
    "\n",
    "# Other parameters\n",
    "parser.add_argument(\n",
    "    \"--data_dir\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"The input data dir. Should contain the .json files for the task.\"\n",
    "    + \"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--train_file\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"The input training file. If a data dir is specified, will look for the file there\"\n",
    "    + \"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--predict_file\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    help=\"The input evaluation file. If a data dir is specified, will look for the file there\"\n",
    "    + \"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tokenizer_name\",\n",
    "    default=\"\",\n",
    "    type=str,\n",
    "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--cache_dir\",\n",
    "    default=\"\",\n",
    "    type=str,\n",
    "    help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--version_2_with_negative\",\n",
    "    action=\"store_true\",\n",
    "    help=\"If true, the SQuAD examples contain some that do not have an answer.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--null_score_diff_threshold\",\n",
    "    type=float,\n",
    "    default=0.0,\n",
    "    help=\"If null_score - best_non_null is greater than the threshold predict null.\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--max_seq_length\",\n",
    "    default=384,\n",
    "    type=int,\n",
    "    help=\"The maximum total input sequence length after WordPiece tokenization. Sequences \"\n",
    "    \"longer than this will be truncated, and sequences shorter than this will be padded.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--doc_stride\",\n",
    "    default=128,\n",
    "    type=int,\n",
    "    help=\"When splitting up a long document into chunks, how much stride to take between chunks.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_query_length\",\n",
    "    default=64,\n",
    "    type=int,\n",
    "    help=\"The maximum number of tokens for the question. Questions longer than this will \"\n",
    "    \"be truncated to this length.\",\n",
    ")\n",
    "parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\n",
    "    \"--evaluate_during_training\", action=\"store_true\", help=\"Run evaluation during training at each logging step.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\n",
    "    \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n",
    ")\n",
    "parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    ")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "parser.add_argument(\n",
    "    \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_steps\",\n",
    "    default=-1,\n",
    "    type=int,\n",
    "    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
    ")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "parser.add_argument(\n",
    "    \"--n_best_size\",\n",
    "    default=20,\n",
    "    type=int,\n",
    "    help=\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_answer_length\",\n",
    "    default=30,\n",
    "    type=int,\n",
    "    help=\"The maximum length of an answer that can be generated. This is needed because the start \"\n",
    "    \"and end predictions are not conditioned on one another.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--verbose_logging\",\n",
    "    action=\"store_true\",\n",
    "    help=\"If true, all of the warnings related to data processing will be printed. \"\n",
    "    \"A number of warnings are expected for a normal SQuAD evaluation.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lang_id\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"language id of input for language-specific xlm models (see tokenization_xlm.PRETRAINED_INIT_CONFIGURATION)\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\")\n",
    "parser.add_argument(\"--save_steps\", type=int, default=500, help=\"Save checkpoint every X updates steps.\")\n",
    "parser.add_argument(\n",
    "    \"--eval_all_checkpoints\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
    ")\n",
    "parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Whether not to use CUDA when available\")\n",
    "parser.add_argument(\n",
    "    \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n",
    ")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "\n",
    "parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"local_rank for distributed training on gpus\")\n",
    "parser.add_argument(\n",
    "    \"--fp16\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fp16_opt_level\",\n",
    "    type=str,\n",
    "    default=\"O1\",\n",
    "    help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "    \"See details at https://nvidia.github.io/apex/amp.html\",\n",
    ")\n",
    "parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"Can be used for distant debugging.\")\n",
    "parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"Can be used for distant debugging.\")\n",
    "parser.add_argument(\"--threads\", type=int, default=1, help=\"multiple threads for converting example to features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n--model_type bert         --model_name_or_path bert-base-uncased         --do_train         --do_eval         --do_lower_case         --train_file $DATA_DIR/train-v1.1.json         --predict_file $DATA_DIR/dev-v1.1.json         --per_gpu_train_batch_size 16         --learning_rate 3e-5         --num_train_epochs 2.0         --max_seq_length 384         --doc_stride 128         --output_dir $EXPERIMENT_DIR/$MODEL_NAME/$DATESTAMP         --threads 12\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "--model_type bert \\\n",
    "        --model_name_or_path bert-base-uncased \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --do_lower_case \\\n",
    "        --train_file $DATA_DIR/train-v1.1.json \\\n",
    "        --predict_file $DATA_DIR/dev-v1.1.json \\\n",
    "        --per_gpu_train_batch_size 16 \\\n",
    "        --learning_rate 3e-5 \\\n",
    "        --num_train_epochs 2.0 \\\n",
    "        --max_seq_length 384 \\\n",
    "        --doc_stride 128 \\\n",
    "        --output_dir $EXPERIMENT_DIR/$MODEL_NAME/$DATESTAMP \\\n",
    "        --threads 12\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"bert\"\n",
    "MODEL_NAME = \"bert-base-cased\"\n",
    "DATESTAMP = \"20200810\"\n",
    "SQUAD_DIR = \"/home/keyur/medhas/squad_data/\"\n",
    "TASK_NAME = \"squad\"\n",
    "PER_DEVICE_BATCH_SIZE = 24\n",
    "EXPERIMENT_DIR=\"/mnt/data/medhas/squad_experiments/%s/%s\"%(MODEL_NAME, DATESTAMP)\n",
    "\n",
    "\n",
    "custom_sysargv = [\n",
    "\"--model_type=%s\"%MODEL_TYPE,\n",
    "\"--model_name_or_path=%s\"%MODEL_NAME,\n",
    "\"--do_train\",\n",
    "\"--do_eval\",\n",
    "\"--do_lower_case\",\n",
    "\"--train_file=%s/train-v1.1.json\"%SQUAD_DIR,\n",
    "\"--predict_file=%s/dev-v1.1.json\"%SQUAD_DIR,\n",
    "\"--max_seq_length=512\",\n",
    "\"--per_gpu_train_batch_size=%s\"%PER_DEVICE_BATCH_SIZE,\n",
    "\"--learning_rate=3e-5\",\n",
    "\"--num_train_epochs=1\",\n",
    "\"--max_seq_length=384\",\n",
    "\"--doc_stride=128\",\n",
    "\"--output_dir=%s\"%EXPERIMENT_DIR,\n",
    "\"--logging_steps=565\",\n",
    "\"--evaluate_during_training\",\n",
    "\"--save_steps=1000\",\n",
    "\"--gradient_accumulation_steps=1\",\n",
    "\"--overwrite_output_dir\",\n",
    "\"--threads=12\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=custom_sysargv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=3e-05, local_rank=-1, logging_steps=565, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='bert-base-cased', model_type='bert', n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=1.0, output_dir='/mnt/data/medhas/squad_experiments/bert-base-cased/20200810', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=24, predict_file='/home/keyur/medhas/squad_data//dev-v1.1.json', save_steps=1000, seed=42, server_ip='', server_port='', threads=12, tokenizer_name='', train_file='/home/keyur/medhas/squad_data//train-v1.1.json', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_type = args.model_type.lower()\n",
    "config = AutoConfig.from_pretrained(\n",
    "    args.config_name if args.config_name else args.model_name_or_path,\n",
    "    cache_dir=args.cache_dir if args.cache_dir else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "        do_lower_case=args.do_lower_case,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.local_rank == 0:\n",
    "    # Make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = args.data_dir if args.data_dir else \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:26<00:00, 16.94it/s]\n"
     ]
    }
   ],
   "source": [
    "processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n",
    "examples = processor.get_train_examples(args.data_dir, filename=args.train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features:   0%|          | 0/87599 [00:00<?, ?it/s]/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "convert squad examples to features: 100%|██████████| 87599/87599 [01:19<00:00, 1101.36it/s]\n",
      "add example index and unique id: 100%|██████████| 87599/87599 [00:00<00:00, 916704.10it/s]\n"
     ]
    }
   ],
   "source": [
    "features, dataset = squad_convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=args.max_seq_length,\n",
    "            doc_stride=args.doc_stride,\n",
    "            max_query_length=args.max_query_length,\n",
    "            is_training=True,\n",
    "            return_dataset=\"pt\",\n",
    "            threads=args.threads,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features:   0%|          | 0/10 [00:00<?, ?it/s]/home/keyur/medhas/transformers/src/transformers/tokenization_utils_base.py:1293: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "convert squad examples to features: 100%|██████████| 10/10 [00:00<00:00, 55.21it/s]\n",
      "add example index and unique id: 100%|██████████| 10/10 [00:00<00:00, 21765.98it/s]\n"
     ]
    }
   ],
   "source": [
    "examples1 = examples[100:110]\n",
    "features1, dataset1 = squad_convert_examples_to_features(\n",
    "            examples=examples1,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=args.max_seq_length,\n",
    "            doc_stride=args.doc_stride,\n",
    "            max_query_length=args.max_query_length,\n",
    "            is_training=True,\n",
    "            return_dataset=\"pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features1)-1):\n",
    "    if (features1[i].qas_id == features1[i+1].qas_id):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_doc_tokens(i):\n",
    "    example = examples1[i]\n",
    "    all_doc_tokens = []\n",
    "    for (i, token) in enumerate(example.doc_tokens):\n",
    "        sub_tokens = tokenizer.tokenize(token)\n",
    "        for sub_token in sub_tokens:\n",
    "            all_doc_tokens.append(sub_token)\n",
    "    return all_doc_tokens\n",
    "\n",
    "\n",
    "def print_squad_feature(i):\n",
    "    print(\"Question Id: \", features1[i].qas_id)\n",
    "    print(\"paragraph_len: \", features1[i].paragraph_len)\n",
    "    print(\"tokens: \", len(features1[i].tokens))\n",
    "    print(\"start_position-end_position: \", features1[i].start_position, features1[i].end_position)\n",
    "    print(\"CLS index: \", features1[i].cls_index)\n",
    "    print(\"Complete context length: \", len(get_all_doc_tokens(features1[i].example_index)))\n",
    "    print(\"Text: \", \" \".join(tokenizer.convert_ids_to_tokens(features1[i].input_ids)))\n",
    "    print(\"Complete Context:\", \" \".join(get_all_doc_tokens(features1[i].example_index)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Id:  573388ce4776f41900660cc3\n",
      "paragraph_len:  360\n",
      "tokens:  384\n",
      "start_position-end_position:  89 92\n",
      "CLS index:  0\n",
      "Complete context length:  368\n",
      "Text:  [CLS] cat ##hol ##ic people identified with not ##re dam ##e , what religious group did people feel ya ##le represented ? [SEP] the success of its football team made not ##re dam ##e a household name . the success of note dam ##e reflected rising status of i ##ris ##h am ##eric ##ans and cat ##hol ##ics in the 1920s . cat ##hol ##ics rallied up around the team and listen to the games on the radio , especially when it knocked off the schools that symbol ##ized the protest ##ant establishment in am ##eric ##a — ha ##rva ##rd , ya ##le , prince ##ton , and army . yet this role as high - profile flagship institution of cat ##hol ##ici ##sm made it an easy target of anti - cat ##hol ##ici ##sm . the most remarkable episode of violence was the clash between not ##re dam ##e students and the k ##u k ##lux k ##lan in 1924 . na ##ti ##vis ##m and anti - cat ##hol ##ici ##sm , especially when directed towards immigrants , were corners ##tones of the k ##k ##k ' s rhetoric , and not ##re dam ##e was seen as a symbol of the threat posed by the cat ##hol ##ic church . the k ##lan decided to have a week - long k ##lav ##ern in south bend . clashes with the student body started on march 17 , when students , aware of the anti - cat ##hol ##ic an ##imo ##sity , blocked the k ##lan ##sm ##en from descending from their trains in the south bend station and ripped the k ##k ##k clothes and re ##gal ##ia . on may 19 thousands of students mass ##ed downtown protesting the k ##lav ##ern , and only the arrival of college president f ##r . mat ##the ##w wa ##ls ##h prevented any further clashes . the next day , football coach kn ##ute rock ##ne spoke at a campus rally and imp ##lore ##d the students to obey the college president and refrain from further violence . a few days later the k ##lav ##ern broke up , but the hostility shown by the students was an o ##men and a contribution to the downfall of the [SEP]\n",
      "Complete Context: the success of its football team made not ##re dam ##e a household name . the success of note dam ##e reflected rising status of i ##ris ##h am ##eric ##ans and cat ##hol ##ics in the 1920s . cat ##hol ##ics rallied up around the team and listen to the games on the radio , especially when it knocked off the schools that symbol ##ized the protest ##ant establishment in am ##eric ##a — ha ##rva ##rd , ya ##le , prince ##ton , and army . yet this role as high - profile flagship institution of cat ##hol ##ici ##sm made it an easy target of anti - cat ##hol ##ici ##sm . the most remarkable episode of violence was the clash between not ##re dam ##e students and the k ##u k ##lux k ##lan in 1924 . na ##ti ##vis ##m and anti - cat ##hol ##ici ##sm , especially when directed towards immigrants , were corners ##tones of the k ##k ##k ' s rhetoric , and not ##re dam ##e was seen as a symbol of the threat posed by the cat ##hol ##ic church . the k ##lan decided to have a week - long k ##lav ##ern in south bend . clashes with the student body started on march 17 , when students , aware of the anti - cat ##hol ##ic an ##imo ##sity , blocked the k ##lan ##sm ##en from descending from their trains in the south bend station and ripped the k ##k ##k clothes and re ##gal ##ia . on may 19 thousands of students mass ##ed downtown protesting the k ##lav ##ern , and only the arrival of college president f ##r . mat ##the ##w wa ##ls ##h prevented any further clashes . the next day , football coach kn ##ute rock ##ne spoke at a campus rally and imp ##lore ##d the students to obey the college president and refrain from further violence . a few days later the k ##lav ##ern broke up , but the hostility shown by the students was an o ##men and a contribution to the downfall of the k ##k ##k in in ##dian ##a .\n"
     ]
    }
   ],
   "source": [
    "print_squad_feature(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Id:  573388ce4776f41900660cc3\n",
      "paragraph_len:  240\n",
      "tokens:  264\n",
      "start_position-end_position:  0 0\n",
      "CLS index:  0\n",
      "Complete context length:  368\n",
      "Text:  [CLS] cat ##hol ##ic people identified with not ##re dam ##e , what religious group did people feel ya ##le represented ? [SEP] ##e students and the k ##u k ##lux k ##lan in 1924 . na ##ti ##vis ##m and anti - cat ##hol ##ici ##sm , especially when directed towards immigrants , were corners ##tones of the k ##k ##k ' s rhetoric , and not ##re dam ##e was seen as a symbol of the threat posed by the cat ##hol ##ic church . the k ##lan decided to have a week - long k ##lav ##ern in south bend . clashes with the student body started on march 17 , when students , aware of the anti - cat ##hol ##ic an ##imo ##sity , blocked the k ##lan ##sm ##en from descending from their trains in the south bend station and ripped the k ##k ##k clothes and re ##gal ##ia . on may 19 thousands of students mass ##ed downtown protesting the k ##lav ##ern , and only the arrival of college president f ##r . mat ##the ##w wa ##ls ##h prevented any further clashes . the next day , football coach kn ##ute rock ##ne spoke at a campus rally and imp ##lore ##d the students to obey the college president and refrain from further violence . a few days later the k ##lav ##ern broke up , but the hostility shown by the students was an o ##men and a contribution to the downfall of the k ##k ##k in in ##dian ##a . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Complete Context: the success of its football team made not ##re dam ##e a household name . the success of note dam ##e reflected rising status of i ##ris ##h am ##eric ##ans and cat ##hol ##ics in the 1920s . cat ##hol ##ics rallied up around the team and listen to the games on the radio , especially when it knocked off the schools that symbol ##ized the protest ##ant establishment in am ##eric ##a — ha ##rva ##rd , ya ##le , prince ##ton , and army . yet this role as high - profile flagship institution of cat ##hol ##ici ##sm made it an easy target of anti - cat ##hol ##ici ##sm . the most remarkable episode of violence was the clash between not ##re dam ##e students and the k ##u k ##lux k ##lan in 1924 . na ##ti ##vis ##m and anti - cat ##hol ##ici ##sm , especially when directed towards immigrants , were corners ##tones of the k ##k ##k ' s rhetoric , and not ##re dam ##e was seen as a symbol of the threat posed by the cat ##hol ##ic church . the k ##lan decided to have a week - long k ##lav ##ern in south bend . clashes with the student body started on march 17 , when students , aware of the anti - cat ##hol ##ic an ##imo ##sity , blocked the k ##lan ##sm ##en from descending from their trains in the south bend station and ripped the k ##k ##k clothes and re ##gal ##ia . on may 19 thousands of students mass ##ed downtown protesting the k ##lav ##ern , and only the arrival of college president f ##r . mat ##the ##w wa ##ls ##h prevented any further clashes . the next day , football coach kn ##ute rock ##ne spoke at a campus rally and imp ##lore ##d the students to obey the college president and refrain from further violence . a few days later the k ##lav ##ern broke up , but the hostility shown by the students was an o ##men and a contribution to the downfall of the k ##k ##k in in ##dian ##a .\n"
     ]
    }
   ],
   "source": [
    "print_squad_feature(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medhas02",
   "language": "python",
   "name": "medhas02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
